{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Student 1 - BUI QUANG PHUONG Linh [qbuiquan@ulb.ac.be](mailto:qbuiquan@ulb.ac.be) - Student ID : 000427796\n",
    "### Student 2 - SINGH Sundeep [susingh@ulb.ac.be](mailto:student2@ulb.ac.be) - Student ID : 000428022\n",
    "\n",
    "## --- Kaggle competition ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the INFO-F422 course, this project is tackling a classification problem which implies different methods of feature selection and models implementation to make predictions. The main purpose is a comparison between those different methods to find which one fits and predicts with the most accuracy. The dataset \"train.csv\" which is used to train the model contains 13083 elements described by 46 features including the \"target\" feature which is our prediction objective. \n",
    "\n",
    "Firstly, different methods of feature selection are implemented to extract the most interesting features in the dataset, which depends of different criteria according to the methods used. In particular, filter methods such as correlation with the output, mRMR as well as wrapper methods are used.   \n",
    "\n",
    "Then, the obtained results in the feature selection will be used to create the predictive models and predict the target following the best extracted features. More precisely, the models implemented are Support Vector Machines (SVM), Random Forests (RF) and Decision Trees. \n",
    "\n",
    "Finally, a combination of different models strategies is carried out to achieve a better overall performance on prediction's accuracy.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running time\n",
    "The <b>whole</b> code (if you try to run the code with \"Cell\" -> \"Run All\") takes about ~20 min to be executed and show all the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the packages if needed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install.packages(\"e1071\")\n",
    "#install.packages(\"rpart\")\n",
    "#install.packages(\"randomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries that will be needed to run the code. \n",
    "- <b>rpart</b>: library that contains Decision Trees model's methods\n",
    "- <b>e1071</b>: library that contains SVM model's methods\n",
    "- <b>randomForest</b>: library that contains Random Forests model's methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n"
     ]
    }
   ],
   "source": [
    "library(e1071)\n",
    "library(rpart)\n",
    "library(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of NA values which are representating missing datas, it may cause troubles in the next steps of prediction such as computing correlation between two variables. To handle this, the following function is replacing those NA values by the mean value of the column (feature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing function that replaces all NA values in the dataset by the mean column value \n",
    "replace_na_with_mean_value<-function(vec) {\n",
    "  mean_vec<-mean(vec,na.rm=T)\n",
    "  vec[is.na(vec)]<-mean_vec\n",
    "  vec\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the training \"train.csv\" and testing \"test.csv\" dataset and preprocess the training set using the previous function. Then, we split in two the training set : \n",
    "- $X$ : contains the whole dataset without the target feature. X is used to train the model with the aim of obtaining the results in Y. \n",
    "- $Y$ : contains only the target feature column. Y is used to compare the real target values with the predicted one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the required data sets\n",
    "\n",
    "full_training <- read.csv(\"train.csv\")\n",
    "test_set <- read.csv(\"test.csv\")\n",
    "full_training<-data.frame(apply(full_training,2,replace_na_with_mean_value))\n",
    "\n",
    "set.seed(3)\n",
    "\n",
    "X<-full_training[,setdiff(colnames(full_training),\"target\")] # Removes the \"target\" column that we want to predict \n",
    "Y<-full_training[,\"target\"] # Contains only the \"target\" column\n",
    "\n",
    "N<-nrow(X)    # Number of elements (examples)\n",
    "n<-ncol(X)    # Number of features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature selection is the process to extract the most relevant subset of features to make the best accurate prediction. Indeed, without this process, the overall model performance tends to decrease with too many inputs especially when learning irrelevant or redundant informations. This problem is well-known and is called <i>overfitting</i>.   \n",
    "\n",
    "Thereby, the feature selection process facilitates data visualization and data understanding by reducing the measurement, storage requirements and training time. Thus, it also proposes a solution to the curse of dimensionality which consists of a phenomena that arise when analyzing and organizing data in high-dimensional spaces which will not occurs in a lower dimensionality. However, this process takes some computation time and then increases the algorithmic complexity. \n",
    "\n",
    "Subsequently, it exists different methods of feature selection : \n",
    "- <b>Filter methods:</b> process used to measure the relevance of the features. The basic idea behind filter methods is to measure the model performance while not using the obtained subset through the process. In filter criteria, all the features are scored and ranked based on certain statistical criteria. The features with the highest ranking values are selected and the low scoring features are removed. Generally, one of the main disadvantage of filter methods is that each feature is considered independently thus ignoring feature dependencies. Some examples of filter methods are principal component analysis (PCA), mRMR, variance thresholds, etc.  \n",
    "\n",
    "</br> \n",
    "\n",
    "- <b>Wrapper methods:</b> compared to filter methods, wrapper methods measure the usefulness of the features. Herein, what we are looking for is a the optimal feature subset to get the best performance using the learning algorithm itself as part of the evaluation function. The evaluation of a specific subset of features is obtained by training and testing a specific classification model. Nevertheless, a huge drawback of these methods is that the complexity is growing exponentially to the feature's number because of the search algorithm to search the space of all feature subsets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, the feature relevance is depending of the correlation between the features values and the target values. The correlation is the relationship between these variables. A positive correlation means that both variables move in the same direction while a negative correlation means that when one variable's value increases, the other variables' values decrease. Nevertheless, in this case, we don't consider these two types of correlation. Whether it is a positive or negative correlation, it is considered as a correlation factor. Thus, we take the absolute values of the correlation value to compare the importance (positive or negative) of the feature variable. Therefore, <b>greater is this correlation, more the feature is relevant for the predictive model</b>.  \n",
    "\n",
    "#### Correlation function \n",
    "By default, the $cor$ function from R is using the <i>Pearson Correlation Coefficient</i>. This method for correlation is computed following this formula: \n",
    "$$ \\rho = \\frac{\\sum_{i=1}^n (x_{i} - \\bar{x})(y_{i} - \\bar{y})}{(n-1) \\sigma_{x} \\sigma_{y}} $$\n",
    "where $n$ is the number of elements, $x_{i}$ the $i^{th}$ features value, $y_{i}$ the $i^{th}$ target value and $\\sigma$ the standard deviation. \n",
    "\n",
    "#### 10-fold cross-validation\n",
    "Cross-validation (fully called $k$-fold cross-validation) is one of the most known method which is estimating the skill of machine learning models. In standard $k$-fold cross-validation, we partition the data into $k$ subsets, called folds. Then, we iteratively train the algorithm on $kâˆ’1$ folds while using the remaining fold as the test set. In this case, the features selection procedure use a 10-folds cross-validation procedure in order to make the ranking. More precisely, the procedure is a resampling method used in order to see how our model performs when some data is missing. Here, we create two different data set one for training and another one for testing. Consequently, we resample the training set each folds and verify the correlation of the features with the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "# 10-fold cross-validation procedure \n",
    "for (i in 1:10) {\n",
    "  \n",
    "  # Testing set\n",
    "  i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "  X.ts<-X[i.ts,]         \n",
    "  Y.ts<-Y[i.ts]  \n",
    "    \n",
    "  # Training set\n",
    "  i.tr<-setdiff(1:N,i.ts)                \n",
    "  X.tr<-X[i.tr,] \n",
    "  Y.tr<-Y[i.tr]                          \n",
    "  \n",
    "  correlation<-abs(cor(X.tr,Y.tr)) # Compute the correlation between the features and the target \n",
    "  ranking<-sort(correlation,decreasing=TRUE,index.return=T)$ix # Sort the features from the most correlated one to the least  \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark concerning the indexes : \n",
    "The index $i$ of the ranking corresponds to the feature whose first column name is $N(i-1)$ because of the \"id\" column that is also considered as a feature and corresponds to the index 1. Thus, for example, the index 21 corresponds to the feature N20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21</li>\n",
       "\t<li>28</li>\n",
       "\t<li>25</li>\n",
       "\t<li>7</li>\n",
       "\t<li>30</li>\n",
       "\t<li>27</li>\n",
       "\t<li>12</li>\n",
       "\t<li>31</li>\n",
       "\t<li>19</li>\n",
       "\t<li>26</li>\n",
       "\t<li>20</li>\n",
       "\t<li>32</li>\n",
       "\t<li>9</li>\n",
       "\t<li>36</li>\n",
       "\t<li>33</li>\n",
       "\t<li>46</li>\n",
       "\t<li>3</li>\n",
       "\t<li>39</li>\n",
       "\t<li>44</li>\n",
       "\t<li>24</li>\n",
       "\t<li>29</li>\n",
       "\t<li>43</li>\n",
       "\t<li>23</li>\n",
       "\t<li>13</li>\n",
       "\t<li>35</li>\n",
       "\t<li>22</li>\n",
       "\t<li>15</li>\n",
       "\t<li>37</li>\n",
       "\t<li>38</li>\n",
       "\t<li>1</li>\n",
       "\t<li>34</li>\n",
       "\t<li>17</li>\n",
       "\t<li>8</li>\n",
       "\t<li>11</li>\n",
       "\t<li>14</li>\n",
       "\t<li>2</li>\n",
       "\t<li>41</li>\n",
       "\t<li>40</li>\n",
       "\t<li>5</li>\n",
       "\t<li>4</li>\n",
       "\t<li>6</li>\n",
       "\t<li>45</li>\n",
       "\t<li>16</li>\n",
       "\t<li>42</li>\n",
       "\t<li>18</li>\n",
       "\t<li>10</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21\n",
       "\\item 28\n",
       "\\item 25\n",
       "\\item 7\n",
       "\\item 30\n",
       "\\item 27\n",
       "\\item 12\n",
       "\\item 31\n",
       "\\item 19\n",
       "\\item 26\n",
       "\\item 20\n",
       "\\item 32\n",
       "\\item 9\n",
       "\\item 36\n",
       "\\item 33\n",
       "\\item 46\n",
       "\\item 3\n",
       "\\item 39\n",
       "\\item 44\n",
       "\\item 24\n",
       "\\item 29\n",
       "\\item 43\n",
       "\\item 23\n",
       "\\item 13\n",
       "\\item 35\n",
       "\\item 22\n",
       "\\item 15\n",
       "\\item 37\n",
       "\\item 38\n",
       "\\item 1\n",
       "\\item 34\n",
       "\\item 17\n",
       "\\item 8\n",
       "\\item 11\n",
       "\\item 14\n",
       "\\item 2\n",
       "\\item 41\n",
       "\\item 40\n",
       "\\item 5\n",
       "\\item 4\n",
       "\\item 6\n",
       "\\item 45\n",
       "\\item 16\n",
       "\\item 42\n",
       "\\item 18\n",
       "\\item 10\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21\n",
       "2. 28\n",
       "3. 25\n",
       "4. 7\n",
       "5. 30\n",
       "6. 27\n",
       "7. 12\n",
       "8. 31\n",
       "9. 19\n",
       "10. 26\n",
       "11. 20\n",
       "12. 32\n",
       "13. 9\n",
       "14. 36\n",
       "15. 33\n",
       "16. 46\n",
       "17. 3\n",
       "18. 39\n",
       "19. 44\n",
       "20. 24\n",
       "21. 29\n",
       "22. 43\n",
       "23. 23\n",
       "24. 13\n",
       "25. 35\n",
       "26. 22\n",
       "27. 15\n",
       "28. 37\n",
       "29. 38\n",
       "30. 1\n",
       "31. 34\n",
       "32. 17\n",
       "33. 8\n",
       "34. 11\n",
       "35. 14\n",
       "36. 2\n",
       "37. 41\n",
       "38. 40\n",
       "39. 5\n",
       "40. 4\n",
       "41. 6\n",
       "42. 45\n",
       "43. 16\n",
       "44. 42\n",
       "45. 18\n",
       "46. 10\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 21 28 25  7 30 27 12 31 19 26 20 32  9 36 33 46  3 39 44 24 29 43 23 13 35\n",
       "[26] 22 15 37 38  1 34 17  8 11 14  2 41 40  5  4  6 45 16 42 18 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>id</th><td>0.0301205960</td></tr>\n",
       "\t<tr><th scope=row>N1</th><td>0.0173303097</td></tr>\n",
       "\t<tr><th scope=row>N2</th><td>0.0580562983</td></tr>\n",
       "\t<tr><th scope=row>N3</th><td>0.0079206310</td></tr>\n",
       "\t<tr><th scope=row>N4</th><td>0.0089693323</td></tr>\n",
       "\t<tr><th scope=row>N5</th><td>0.0075886052</td></tr>\n",
       "\t<tr><th scope=row>N6</th><td>0.0978932162</td></tr>\n",
       "\t<tr><th scope=row>N7</th><td>0.0231060763</td></tr>\n",
       "\t<tr><th scope=row>N8</th><td>0.0665630992</td></tr>\n",
       "\t<tr><th scope=row>N9</th><td>0.0001310887</td></tr>\n",
       "\t<tr><th scope=row>N10</th><td>0.0220398258</td></tr>\n",
       "\t<tr><th scope=row>N11</th><td>0.0795464211</td></tr>\n",
       "\t<tr><th scope=row>N12</th><td>0.0461007899</td></tr>\n",
       "\t<tr><th scope=row>N13</th><td>0.0194307244</td></tr>\n",
       "\t<tr><th scope=row>N14</th><td>0.0388833824</td></tr>\n",
       "\t<tr><th scope=row>N15</th><td>0.0036844742</td></tr>\n",
       "\t<tr><th scope=row>N16</th><td>0.0267700247</td></tr>\n",
       "\t<tr><th scope=row>N17</th><td>0.0002092429</td></tr>\n",
       "\t<tr><th scope=row>N18</th><td>0.0759522902</td></tr>\n",
       "\t<tr><th scope=row>N19</th><td>0.0717033385</td></tr>\n",
       "\t<tr><th scope=row>N20</th><td>0.1591994366</td></tr>\n",
       "\t<tr><th scope=row>N21</th><td>0.0423485059</td></tr>\n",
       "\t<tr><th scope=row>N22</th><td>0.0470414823</td></tr>\n",
       "\t<tr><th scope=row>N23</th><td>0.0516055301</td></tr>\n",
       "\t<tr><th scope=row>N24</th><td>0.1424325042</td></tr>\n",
       "\t<tr><th scope=row>N25</th><td>0.0746933622</td></tr>\n",
       "\t<tr><th scope=row>N26</th><td>0.0832030243</td></tr>\n",
       "\t<tr><th scope=row>N27</th><td>0.1464617760</td></tr>\n",
       "\t<tr><th scope=row>N28</th><td>0.0505572418</td></tr>\n",
       "\t<tr><th scope=row>N29</th><td>0.0845777330</td></tr>\n",
       "\t<tr><th scope=row>N30</th><td>0.0762258913</td></tr>\n",
       "\t<tr><th scope=row>N31</th><td>0.0704473159</td></tr>\n",
       "\t<tr><th scope=row>N32</th><td>0.0618275986</td></tr>\n",
       "\t<tr><th scope=row>N33</th><td>0.0277288069</td></tr>\n",
       "\t<tr><th scope=row>N34</th><td>0.0450656444</td></tr>\n",
       "\t<tr><th scope=row>N35</th><td>0.0630245978</td></tr>\n",
       "\t<tr><th scope=row>N36</th><td>0.0359316303</td></tr>\n",
       "\t<tr><th scope=row>N37</th><td>0.0325732721</td></tr>\n",
       "\t<tr><th scope=row>N38</th><td>0.0561908519</td></tr>\n",
       "\t<tr><th scope=row>N39</th><td>0.0148684661</td></tr>\n",
       "\t<tr><th scope=row>N40</th><td>0.0151409012</td></tr>\n",
       "\t<tr><th scope=row>N41</th><td>0.0031107219</td></tr>\n",
       "\t<tr><th scope=row>N42</th><td>0.0503421432</td></tr>\n",
       "\t<tr><th scope=row>N43</th><td>0.0547098758</td></tr>\n",
       "\t<tr><th scope=row>N44</th><td>0.0049793970</td></tr>\n",
       "\t<tr><th scope=row>N45</th><td>0.0589280985</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\tid & 0.0301205960\\\\\n",
       "\tN1 & 0.0173303097\\\\\n",
       "\tN2 & 0.0580562983\\\\\n",
       "\tN3 & 0.0079206310\\\\\n",
       "\tN4 & 0.0089693323\\\\\n",
       "\tN5 & 0.0075886052\\\\\n",
       "\tN6 & 0.0978932162\\\\\n",
       "\tN7 & 0.0231060763\\\\\n",
       "\tN8 & 0.0665630992\\\\\n",
       "\tN9 & 0.0001310887\\\\\n",
       "\tN10 & 0.0220398258\\\\\n",
       "\tN11 & 0.0795464211\\\\\n",
       "\tN12 & 0.0461007899\\\\\n",
       "\tN13 & 0.0194307244\\\\\n",
       "\tN14 & 0.0388833824\\\\\n",
       "\tN15 & 0.0036844742\\\\\n",
       "\tN16 & 0.0267700247\\\\\n",
       "\tN17 & 0.0002092429\\\\\n",
       "\tN18 & 0.0759522902\\\\\n",
       "\tN19 & 0.0717033385\\\\\n",
       "\tN20 & 0.1591994366\\\\\n",
       "\tN21 & 0.0423485059\\\\\n",
       "\tN22 & 0.0470414823\\\\\n",
       "\tN23 & 0.0516055301\\\\\n",
       "\tN24 & 0.1424325042\\\\\n",
       "\tN25 & 0.0746933622\\\\\n",
       "\tN26 & 0.0832030243\\\\\n",
       "\tN27 & 0.1464617760\\\\\n",
       "\tN28 & 0.0505572418\\\\\n",
       "\tN29 & 0.0845777330\\\\\n",
       "\tN30 & 0.0762258913\\\\\n",
       "\tN31 & 0.0704473159\\\\\n",
       "\tN32 & 0.0618275986\\\\\n",
       "\tN33 & 0.0277288069\\\\\n",
       "\tN34 & 0.0450656444\\\\\n",
       "\tN35 & 0.0630245978\\\\\n",
       "\tN36 & 0.0359316303\\\\\n",
       "\tN37 & 0.0325732721\\\\\n",
       "\tN38 & 0.0561908519\\\\\n",
       "\tN39 & 0.0148684661\\\\\n",
       "\tN40 & 0.0151409012\\\\\n",
       "\tN41 & 0.0031107219\\\\\n",
       "\tN42 & 0.0503421432\\\\\n",
       "\tN43 & 0.0547098758\\\\\n",
       "\tN44 & 0.0049793970\\\\\n",
       "\tN45 & 0.0589280985\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| id | 0.0301205960 |\n",
       "| N1 | 0.0173303097 |\n",
       "| N2 | 0.0580562983 |\n",
       "| N3 | 0.0079206310 |\n",
       "| N4 | 0.0089693323 |\n",
       "| N5 | 0.0075886052 |\n",
       "| N6 | 0.0978932162 |\n",
       "| N7 | 0.0231060763 |\n",
       "| N8 | 0.0665630992 |\n",
       "| N9 | 0.0001310887 |\n",
       "| N10 | 0.0220398258 |\n",
       "| N11 | 0.0795464211 |\n",
       "| N12 | 0.0461007899 |\n",
       "| N13 | 0.0194307244 |\n",
       "| N14 | 0.0388833824 |\n",
       "| N15 | 0.0036844742 |\n",
       "| N16 | 0.0267700247 |\n",
       "| N17 | 0.0002092429 |\n",
       "| N18 | 0.0759522902 |\n",
       "| N19 | 0.0717033385 |\n",
       "| N20 | 0.1591994366 |\n",
       "| N21 | 0.0423485059 |\n",
       "| N22 | 0.0470414823 |\n",
       "| N23 | 0.0516055301 |\n",
       "| N24 | 0.1424325042 |\n",
       "| N25 | 0.0746933622 |\n",
       "| N26 | 0.0832030243 |\n",
       "| N27 | 0.1464617760 |\n",
       "| N28 | 0.0505572418 |\n",
       "| N29 | 0.0845777330 |\n",
       "| N30 | 0.0762258913 |\n",
       "| N31 | 0.0704473159 |\n",
       "| N32 | 0.0618275986 |\n",
       "| N33 | 0.0277288069 |\n",
       "| N34 | 0.0450656444 |\n",
       "| N35 | 0.0630245978 |\n",
       "| N36 | 0.0359316303 |\n",
       "| N37 | 0.0325732721 |\n",
       "| N38 | 0.0561908519 |\n",
       "| N39 | 0.0148684661 |\n",
       "| N40 | 0.0151409012 |\n",
       "| N41 | 0.0031107219 |\n",
       "| N42 | 0.0503421432 |\n",
       "| N43 | 0.0547098758 |\n",
       "| N44 | 0.0049793970 |\n",
       "| N45 | 0.0589280985 |\n",
       "\n"
      ],
      "text/plain": [
       "    [,1]        \n",
       "id  0.0301205960\n",
       "N1  0.0173303097\n",
       "N2  0.0580562983\n",
       "N3  0.0079206310\n",
       "N4  0.0089693323\n",
       "N5  0.0075886052\n",
       "N6  0.0978932162\n",
       "N7  0.0231060763\n",
       "N8  0.0665630992\n",
       "N9  0.0001310887\n",
       "N10 0.0220398258\n",
       "N11 0.0795464211\n",
       "N12 0.0461007899\n",
       "N13 0.0194307244\n",
       "N14 0.0388833824\n",
       "N15 0.0036844742\n",
       "N16 0.0267700247\n",
       "N17 0.0002092429\n",
       "N18 0.0759522902\n",
       "N19 0.0717033385\n",
       "N20 0.1591994366\n",
       "N21 0.0423485059\n",
       "N22 0.0470414823\n",
       "N23 0.0516055301\n",
       "N24 0.1424325042\n",
       "N25 0.0746933622\n",
       "N26 0.0832030243\n",
       "N27 0.1464617760\n",
       "N28 0.0505572418\n",
       "N29 0.0845777330\n",
       "N30 0.0762258913\n",
       "N31 0.0704473159\n",
       "N32 0.0618275986\n",
       "N33 0.0277288069\n",
       "N34 0.0450656444\n",
       "N35 0.0630245978\n",
       "N36 0.0359316303\n",
       "N37 0.0325732721\n",
       "N38 0.0561908519\n",
       "N39 0.0148684661\n",
       "N40 0.0151409012\n",
       "N41 0.0031107219\n",
       "N42 0.0503421432\n",
       "N43 0.0547098758\n",
       "N44 0.0049793970\n",
       "N45 0.0589280985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features with correlations with the output \n",
    "\n",
    "In order to use the best features found for prediction, here is the 30 best features. These 30 features will be given as data to create the predictive model. Note that this value of 30 is not arbitrary. Indeed, we have tried to predict in the next section with different numbers of top features: 10, 15, 20, 25, 30 and 35. Overall, 30 seems to be the best number of features to get the best performance. That is the reason why we have chosen to take the 30 top features to create the models in the next section.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'N20'</li>\n",
       "\t<li>'N27'</li>\n",
       "\t<li>'N24'</li>\n",
       "\t<li>'N6'</li>\n",
       "\t<li>'N29'</li>\n",
       "\t<li>'N26'</li>\n",
       "\t<li>'N11'</li>\n",
       "\t<li>'N30'</li>\n",
       "\t<li>'N18'</li>\n",
       "\t<li>'N25'</li>\n",
       "\t<li>'N19'</li>\n",
       "\t<li>'N31'</li>\n",
       "\t<li>'N8'</li>\n",
       "\t<li>'N35'</li>\n",
       "\t<li>'N32'</li>\n",
       "\t<li>'N45'</li>\n",
       "\t<li>'N2'</li>\n",
       "\t<li>'N38'</li>\n",
       "\t<li>'N43'</li>\n",
       "\t<li>'N23'</li>\n",
       "\t<li>'N28'</li>\n",
       "\t<li>'N42'</li>\n",
       "\t<li>'N22'</li>\n",
       "\t<li>'N12'</li>\n",
       "\t<li>'N34'</li>\n",
       "\t<li>'N21'</li>\n",
       "\t<li>'N14'</li>\n",
       "\t<li>'N36'</li>\n",
       "\t<li>'N37'</li>\n",
       "\t<li>'id'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'N20'\n",
       "\\item 'N27'\n",
       "\\item 'N24'\n",
       "\\item 'N6'\n",
       "\\item 'N29'\n",
       "\\item 'N26'\n",
       "\\item 'N11'\n",
       "\\item 'N30'\n",
       "\\item 'N18'\n",
       "\\item 'N25'\n",
       "\\item 'N19'\n",
       "\\item 'N31'\n",
       "\\item 'N8'\n",
       "\\item 'N35'\n",
       "\\item 'N32'\n",
       "\\item 'N45'\n",
       "\\item 'N2'\n",
       "\\item 'N38'\n",
       "\\item 'N43'\n",
       "\\item 'N23'\n",
       "\\item 'N28'\n",
       "\\item 'N42'\n",
       "\\item 'N22'\n",
       "\\item 'N12'\n",
       "\\item 'N34'\n",
       "\\item 'N21'\n",
       "\\item 'N14'\n",
       "\\item 'N36'\n",
       "\\item 'N37'\n",
       "\\item 'id'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'N20'\n",
       "2. 'N27'\n",
       "3. 'N24'\n",
       "4. 'N6'\n",
       "5. 'N29'\n",
       "6. 'N26'\n",
       "7. 'N11'\n",
       "8. 'N30'\n",
       "9. 'N18'\n",
       "10. 'N25'\n",
       "11. 'N19'\n",
       "12. 'N31'\n",
       "13. 'N8'\n",
       "14. 'N35'\n",
       "15. 'N32'\n",
       "16. 'N45'\n",
       "17. 'N2'\n",
       "18. 'N38'\n",
       "19. 'N43'\n",
       "20. 'N23'\n",
       "21. 'N28'\n",
       "22. 'N42'\n",
       "23. 'N22'\n",
       "24. 'N12'\n",
       "25. 'N34'\n",
       "26. 'N21'\n",
       "27. 'N14'\n",
       "28. 'N36'\n",
       "29. 'N37'\n",
       "30. 'id'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"N20\" \"N27\" \"N24\" \"N6\"  \"N29\" \"N26\" \"N11\" \"N30\" \"N18\" \"N25\" \"N19\" \"N31\"\n",
       "[13] \"N8\"  \"N35\" \"N32\" \"N45\" \"N2\"  \"N38\" \"N43\" \"N23\" \"N28\" \"N42\" \"N22\" \"N12\"\n",
       "[25] \"N34\" \"N21\" \"N14\" \"N36\" \"N37\" \"id\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ord <- ranking[0:30]\n",
    "x30 <- X.tr[,ord]\n",
    "names(x30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mRMR\n",
    "\n",
    "This method creates a ranking by considering the correlations with the output but adds some precision to it. More precisely, mRMR will also avoid redudant varibles by adding a phase of post processing to the method of \"correlation with the output\". Therefore, the method will take the ranking made and substract a redundance score to it which is computed as the mean of the correlation between one feature and all the other features. Then, the feature left with the max value after the substraction is taken as a top feature and we do the same with this feature. In other words, we take this feature and compute the redundancy score accompagnied by the substraction until we get our new top ranking. More formally, the computation of the redundancy $W_{c}$ is done following this formula: \n",
    "$$ W_{c} = \\frac{1}{n} \\sum_{i,j} | c(i,j) | $$ \n",
    "where $n$ is the number of features (columns) and $c(i,j)$ the correlation between the variable $i$ and $j$. \n",
    "\n",
    "To summarize, the signification of mRMR does it well: <b>m</b>inimum <b>R</b>edundancy <b>M</b>aximum <b>R</b>elevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "# 10-fold cross-validation process\n",
    "for (i in 1:10) {\n",
    "    \n",
    "    # Testing Set \n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "    \n",
    "    # Training Set\n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "    \n",
    "    mRMR.correlation<-abs(cor(X.tr,Y.tr)) # Compute the correlation between the features and the target\n",
    "    \n",
    "    selected<-c()\n",
    "    candidates<-1:n # The candidates list are all the features but after every round the best feature is removed\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n) {\n",
    "        redudancy.score<-numeric(length(candidates)) \n",
    "        if (length(selected)>0) {\n",
    "            cor.selected.candidates<-cor(X.tr[,selected,drop=F],X.tr[,candidates,drop=F])\n",
    "            redudancy.score<-apply(cor.selected.candidates,2,mean) #update redundancy score\n",
    "        }\n",
    "        \n",
    "        mRMR.score<-mRMR.correlation[candidates]-redudancy.score #update mrMR score\n",
    "        \n",
    "        selected_current<-candidates[which.max(mRMR.score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        candidates<-setdiff(candidates,selected_current) # remove best feature from candidates \n",
    "    }\n",
    "    \n",
    "    mRMR.ranking<-selected\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21</li>\n",
       "\t<li>28</li>\n",
       "\t<li>30</li>\n",
       "\t<li>26</li>\n",
       "\t<li>27</li>\n",
       "\t<li>29</li>\n",
       "\t<li>25</li>\n",
       "\t<li>13</li>\n",
       "\t<li>17</li>\n",
       "\t<li>7</li>\n",
       "\t<li>32</li>\n",
       "\t<li>36</li>\n",
       "\t<li>12</li>\n",
       "\t<li>41</li>\n",
       "\t<li>19</li>\n",
       "\t<li>3</li>\n",
       "\t<li>46</li>\n",
       "\t<li>24</li>\n",
       "\t<li>33</li>\n",
       "\t<li>38</li>\n",
       "\t<li>45</li>\n",
       "\t<li>2</li>\n",
       "\t<li>44</li>\n",
       "\t<li>34</li>\n",
       "\t<li>40</li>\n",
       "\t<li>31</li>\n",
       "\t<li>9</li>\n",
       "\t<li>1</li>\n",
       "\t<li>15</li>\n",
       "\t<li>35</li>\n",
       "\t<li>43</li>\n",
       "\t<li>5</li>\n",
       "\t<li>22</li>\n",
       "\t<li>20</li>\n",
       "\t<li>16</li>\n",
       "\t<li>42</li>\n",
       "\t<li>23</li>\n",
       "\t<li>39</li>\n",
       "\t<li>4</li>\n",
       "\t<li>8</li>\n",
       "\t<li>10</li>\n",
       "\t<li>11</li>\n",
       "\t<li>14</li>\n",
       "\t<li>18</li>\n",
       "\t<li>6</li>\n",
       "\t<li>37</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21\n",
       "\\item 28\n",
       "\\item 30\n",
       "\\item 26\n",
       "\\item 27\n",
       "\\item 29\n",
       "\\item 25\n",
       "\\item 13\n",
       "\\item 17\n",
       "\\item 7\n",
       "\\item 32\n",
       "\\item 36\n",
       "\\item 12\n",
       "\\item 41\n",
       "\\item 19\n",
       "\\item 3\n",
       "\\item 46\n",
       "\\item 24\n",
       "\\item 33\n",
       "\\item 38\n",
       "\\item 45\n",
       "\\item 2\n",
       "\\item 44\n",
       "\\item 34\n",
       "\\item 40\n",
       "\\item 31\n",
       "\\item 9\n",
       "\\item 1\n",
       "\\item 15\n",
       "\\item 35\n",
       "\\item 43\n",
       "\\item 5\n",
       "\\item 22\n",
       "\\item 20\n",
       "\\item 16\n",
       "\\item 42\n",
       "\\item 23\n",
       "\\item 39\n",
       "\\item 4\n",
       "\\item 8\n",
       "\\item 10\n",
       "\\item 11\n",
       "\\item 14\n",
       "\\item 18\n",
       "\\item 6\n",
       "\\item 37\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21\n",
       "2. 28\n",
       "3. 30\n",
       "4. 26\n",
       "5. 27\n",
       "6. 29\n",
       "7. 25\n",
       "8. 13\n",
       "9. 17\n",
       "10. 7\n",
       "11. 32\n",
       "12. 36\n",
       "13. 12\n",
       "14. 41\n",
       "15. 19\n",
       "16. 3\n",
       "17. 46\n",
       "18. 24\n",
       "19. 33\n",
       "20. 38\n",
       "21. 45\n",
       "22. 2\n",
       "23. 44\n",
       "24. 34\n",
       "25. 40\n",
       "26. 31\n",
       "27. 9\n",
       "28. 1\n",
       "29. 15\n",
       "30. 35\n",
       "31. 43\n",
       "32. 5\n",
       "33. 22\n",
       "34. 20\n",
       "35. 16\n",
       "36. 42\n",
       "37. 23\n",
       "38. 39\n",
       "39. 4\n",
       "40. 8\n",
       "41. 10\n",
       "42. 11\n",
       "43. 14\n",
       "44. 18\n",
       "45. 6\n",
       "46. 37\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 21 28 30 26 27 29 25 13 17  7 32 36 12 41 19  3 46 24 33 38 45  2 44 34 40\n",
       "[26] 31  9  1 15 35 43  5 22 20 16 42 23 39  4  8 10 11 14 18  6 37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mRMR.ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>id</th><td>0.0301205960</td></tr>\n",
       "\t<tr><th scope=row>N1</th><td>0.0173303097</td></tr>\n",
       "\t<tr><th scope=row>N2</th><td>0.0580562983</td></tr>\n",
       "\t<tr><th scope=row>N3</th><td>0.0079206310</td></tr>\n",
       "\t<tr><th scope=row>N4</th><td>0.0089693323</td></tr>\n",
       "\t<tr><th scope=row>N5</th><td>0.0075886052</td></tr>\n",
       "\t<tr><th scope=row>N6</th><td>0.0978932162</td></tr>\n",
       "\t<tr><th scope=row>N7</th><td>0.0231060763</td></tr>\n",
       "\t<tr><th scope=row>N8</th><td>0.0665630992</td></tr>\n",
       "\t<tr><th scope=row>N9</th><td>0.0001310887</td></tr>\n",
       "\t<tr><th scope=row>N10</th><td>0.0220398258</td></tr>\n",
       "\t<tr><th scope=row>N11</th><td>0.0795464211</td></tr>\n",
       "\t<tr><th scope=row>N12</th><td>0.0461007899</td></tr>\n",
       "\t<tr><th scope=row>N13</th><td>0.0194307244</td></tr>\n",
       "\t<tr><th scope=row>N14</th><td>0.0388833824</td></tr>\n",
       "\t<tr><th scope=row>N15</th><td>0.0036844742</td></tr>\n",
       "\t<tr><th scope=row>N16</th><td>0.0267700247</td></tr>\n",
       "\t<tr><th scope=row>N17</th><td>0.0002092429</td></tr>\n",
       "\t<tr><th scope=row>N18</th><td>0.0759522902</td></tr>\n",
       "\t<tr><th scope=row>N19</th><td>0.0717033385</td></tr>\n",
       "\t<tr><th scope=row>N20</th><td>0.1591994366</td></tr>\n",
       "\t<tr><th scope=row>N21</th><td>0.0423485059</td></tr>\n",
       "\t<tr><th scope=row>N22</th><td>0.0470414823</td></tr>\n",
       "\t<tr><th scope=row>N23</th><td>0.0516055301</td></tr>\n",
       "\t<tr><th scope=row>N24</th><td>0.1424325042</td></tr>\n",
       "\t<tr><th scope=row>N25</th><td>0.0746933622</td></tr>\n",
       "\t<tr><th scope=row>N26</th><td>0.0832030243</td></tr>\n",
       "\t<tr><th scope=row>N27</th><td>0.1464617760</td></tr>\n",
       "\t<tr><th scope=row>N28</th><td>0.0505572418</td></tr>\n",
       "\t<tr><th scope=row>N29</th><td>0.0845777330</td></tr>\n",
       "\t<tr><th scope=row>N30</th><td>0.0762258913</td></tr>\n",
       "\t<tr><th scope=row>N31</th><td>0.0704473159</td></tr>\n",
       "\t<tr><th scope=row>N32</th><td>0.0618275986</td></tr>\n",
       "\t<tr><th scope=row>N33</th><td>0.0277288069</td></tr>\n",
       "\t<tr><th scope=row>N34</th><td>0.0450656444</td></tr>\n",
       "\t<tr><th scope=row>N35</th><td>0.0630245978</td></tr>\n",
       "\t<tr><th scope=row>N36</th><td>0.0359316303</td></tr>\n",
       "\t<tr><th scope=row>N37</th><td>0.0325732721</td></tr>\n",
       "\t<tr><th scope=row>N38</th><td>0.0561908519</td></tr>\n",
       "\t<tr><th scope=row>N39</th><td>0.0148684661</td></tr>\n",
       "\t<tr><th scope=row>N40</th><td>0.0151409012</td></tr>\n",
       "\t<tr><th scope=row>N41</th><td>0.0031107219</td></tr>\n",
       "\t<tr><th scope=row>N42</th><td>0.0503421432</td></tr>\n",
       "\t<tr><th scope=row>N43</th><td>0.0547098758</td></tr>\n",
       "\t<tr><th scope=row>N44</th><td>0.0049793970</td></tr>\n",
       "\t<tr><th scope=row>N45</th><td>0.0589280985</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "\tid & 0.0301205960\\\\\n",
       "\tN1 & 0.0173303097\\\\\n",
       "\tN2 & 0.0580562983\\\\\n",
       "\tN3 & 0.0079206310\\\\\n",
       "\tN4 & 0.0089693323\\\\\n",
       "\tN5 & 0.0075886052\\\\\n",
       "\tN6 & 0.0978932162\\\\\n",
       "\tN7 & 0.0231060763\\\\\n",
       "\tN8 & 0.0665630992\\\\\n",
       "\tN9 & 0.0001310887\\\\\n",
       "\tN10 & 0.0220398258\\\\\n",
       "\tN11 & 0.0795464211\\\\\n",
       "\tN12 & 0.0461007899\\\\\n",
       "\tN13 & 0.0194307244\\\\\n",
       "\tN14 & 0.0388833824\\\\\n",
       "\tN15 & 0.0036844742\\\\\n",
       "\tN16 & 0.0267700247\\\\\n",
       "\tN17 & 0.0002092429\\\\\n",
       "\tN18 & 0.0759522902\\\\\n",
       "\tN19 & 0.0717033385\\\\\n",
       "\tN20 & 0.1591994366\\\\\n",
       "\tN21 & 0.0423485059\\\\\n",
       "\tN22 & 0.0470414823\\\\\n",
       "\tN23 & 0.0516055301\\\\\n",
       "\tN24 & 0.1424325042\\\\\n",
       "\tN25 & 0.0746933622\\\\\n",
       "\tN26 & 0.0832030243\\\\\n",
       "\tN27 & 0.1464617760\\\\\n",
       "\tN28 & 0.0505572418\\\\\n",
       "\tN29 & 0.0845777330\\\\\n",
       "\tN30 & 0.0762258913\\\\\n",
       "\tN31 & 0.0704473159\\\\\n",
       "\tN32 & 0.0618275986\\\\\n",
       "\tN33 & 0.0277288069\\\\\n",
       "\tN34 & 0.0450656444\\\\\n",
       "\tN35 & 0.0630245978\\\\\n",
       "\tN36 & 0.0359316303\\\\\n",
       "\tN37 & 0.0325732721\\\\\n",
       "\tN38 & 0.0561908519\\\\\n",
       "\tN39 & 0.0148684661\\\\\n",
       "\tN40 & 0.0151409012\\\\\n",
       "\tN41 & 0.0031107219\\\\\n",
       "\tN42 & 0.0503421432\\\\\n",
       "\tN43 & 0.0547098758\\\\\n",
       "\tN44 & 0.0049793970\\\\\n",
       "\tN45 & 0.0589280985\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| id | 0.0301205960 |\n",
       "| N1 | 0.0173303097 |\n",
       "| N2 | 0.0580562983 |\n",
       "| N3 | 0.0079206310 |\n",
       "| N4 | 0.0089693323 |\n",
       "| N5 | 0.0075886052 |\n",
       "| N6 | 0.0978932162 |\n",
       "| N7 | 0.0231060763 |\n",
       "| N8 | 0.0665630992 |\n",
       "| N9 | 0.0001310887 |\n",
       "| N10 | 0.0220398258 |\n",
       "| N11 | 0.0795464211 |\n",
       "| N12 | 0.0461007899 |\n",
       "| N13 | 0.0194307244 |\n",
       "| N14 | 0.0388833824 |\n",
       "| N15 | 0.0036844742 |\n",
       "| N16 | 0.0267700247 |\n",
       "| N17 | 0.0002092429 |\n",
       "| N18 | 0.0759522902 |\n",
       "| N19 | 0.0717033385 |\n",
       "| N20 | 0.1591994366 |\n",
       "| N21 | 0.0423485059 |\n",
       "| N22 | 0.0470414823 |\n",
       "| N23 | 0.0516055301 |\n",
       "| N24 | 0.1424325042 |\n",
       "| N25 | 0.0746933622 |\n",
       "| N26 | 0.0832030243 |\n",
       "| N27 | 0.1464617760 |\n",
       "| N28 | 0.0505572418 |\n",
       "| N29 | 0.0845777330 |\n",
       "| N30 | 0.0762258913 |\n",
       "| N31 | 0.0704473159 |\n",
       "| N32 | 0.0618275986 |\n",
       "| N33 | 0.0277288069 |\n",
       "| N34 | 0.0450656444 |\n",
       "| N35 | 0.0630245978 |\n",
       "| N36 | 0.0359316303 |\n",
       "| N37 | 0.0325732721 |\n",
       "| N38 | 0.0561908519 |\n",
       "| N39 | 0.0148684661 |\n",
       "| N40 | 0.0151409012 |\n",
       "| N41 | 0.0031107219 |\n",
       "| N42 | 0.0503421432 |\n",
       "| N43 | 0.0547098758 |\n",
       "| N44 | 0.0049793970 |\n",
       "| N45 | 0.0589280985 |\n",
       "\n"
      ],
      "text/plain": [
       "    [,1]        \n",
       "id  0.0301205960\n",
       "N1  0.0173303097\n",
       "N2  0.0580562983\n",
       "N3  0.0079206310\n",
       "N4  0.0089693323\n",
       "N5  0.0075886052\n",
       "N6  0.0978932162\n",
       "N7  0.0231060763\n",
       "N8  0.0665630992\n",
       "N9  0.0001310887\n",
       "N10 0.0220398258\n",
       "N11 0.0795464211\n",
       "N12 0.0461007899\n",
       "N13 0.0194307244\n",
       "N14 0.0388833824\n",
       "N15 0.0036844742\n",
       "N16 0.0267700247\n",
       "N17 0.0002092429\n",
       "N18 0.0759522902\n",
       "N19 0.0717033385\n",
       "N20 0.1591994366\n",
       "N21 0.0423485059\n",
       "N22 0.0470414823\n",
       "N23 0.0516055301\n",
       "N24 0.1424325042\n",
       "N25 0.0746933622\n",
       "N26 0.0832030243\n",
       "N27 0.1464617760\n",
       "N28 0.0505572418\n",
       "N29 0.0845777330\n",
       "N30 0.0762258913\n",
       "N31 0.0704473159\n",
       "N32 0.0618275986\n",
       "N33 0.0277288069\n",
       "N34 0.0450656444\n",
       "N35 0.0630245978\n",
       "N36 0.0359316303\n",
       "N37 0.0325732721\n",
       "N38 0.0561908519\n",
       "N39 0.0148684661\n",
       "N40 0.0151409012\n",
       "N41 0.0031107219\n",
       "N42 0.0503421432\n",
       "N43 0.0547098758\n",
       "N44 0.0049793970\n",
       "N45 0.0589280985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mRMR.correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features with mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'N20'</li>\n",
       "\t<li>'N27'</li>\n",
       "\t<li>'N29'</li>\n",
       "\t<li>'N25'</li>\n",
       "\t<li>'N26'</li>\n",
       "\t<li>'N28'</li>\n",
       "\t<li>'N24'</li>\n",
       "\t<li>'N12'</li>\n",
       "\t<li>'N16'</li>\n",
       "\t<li>'N6'</li>\n",
       "\t<li>'N31'</li>\n",
       "\t<li>'N35'</li>\n",
       "\t<li>'N11'</li>\n",
       "\t<li>'N40'</li>\n",
       "\t<li>'N18'</li>\n",
       "\t<li>'N2'</li>\n",
       "\t<li>'N45'</li>\n",
       "\t<li>'N23'</li>\n",
       "\t<li>'N32'</li>\n",
       "\t<li>'N37'</li>\n",
       "\t<li>'N44'</li>\n",
       "\t<li>'N1'</li>\n",
       "\t<li>'N43'</li>\n",
       "\t<li>'N33'</li>\n",
       "\t<li>'N39'</li>\n",
       "\t<li>'N30'</li>\n",
       "\t<li>'N8'</li>\n",
       "\t<li>'id'</li>\n",
       "\t<li>'N14'</li>\n",
       "\t<li>'N34'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'N20'\n",
       "\\item 'N27'\n",
       "\\item 'N29'\n",
       "\\item 'N25'\n",
       "\\item 'N26'\n",
       "\\item 'N28'\n",
       "\\item 'N24'\n",
       "\\item 'N12'\n",
       "\\item 'N16'\n",
       "\\item 'N6'\n",
       "\\item 'N31'\n",
       "\\item 'N35'\n",
       "\\item 'N11'\n",
       "\\item 'N40'\n",
       "\\item 'N18'\n",
       "\\item 'N2'\n",
       "\\item 'N45'\n",
       "\\item 'N23'\n",
       "\\item 'N32'\n",
       "\\item 'N37'\n",
       "\\item 'N44'\n",
       "\\item 'N1'\n",
       "\\item 'N43'\n",
       "\\item 'N33'\n",
       "\\item 'N39'\n",
       "\\item 'N30'\n",
       "\\item 'N8'\n",
       "\\item 'id'\n",
       "\\item 'N14'\n",
       "\\item 'N34'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'N20'\n",
       "2. 'N27'\n",
       "3. 'N29'\n",
       "4. 'N25'\n",
       "5. 'N26'\n",
       "6. 'N28'\n",
       "7. 'N24'\n",
       "8. 'N12'\n",
       "9. 'N16'\n",
       "10. 'N6'\n",
       "11. 'N31'\n",
       "12. 'N35'\n",
       "13. 'N11'\n",
       "14. 'N40'\n",
       "15. 'N18'\n",
       "16. 'N2'\n",
       "17. 'N45'\n",
       "18. 'N23'\n",
       "19. 'N32'\n",
       "20. 'N37'\n",
       "21. 'N44'\n",
       "22. 'N1'\n",
       "23. 'N43'\n",
       "24. 'N33'\n",
       "25. 'N39'\n",
       "26. 'N30'\n",
       "27. 'N8'\n",
       "28. 'id'\n",
       "29. 'N14'\n",
       "30. 'N34'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"N20\" \"N27\" \"N29\" \"N25\" \"N26\" \"N28\" \"N24\" \"N12\" \"N16\" \"N6\"  \"N31\" \"N35\"\n",
       "[13] \"N11\" \"N40\" \"N18\" \"N2\"  \"N45\" \"N23\" \"N32\" \"N37\" \"N44\" \"N1\"  \"N43\" \"N33\"\n",
       "[25] \"N39\" \"N30\" \"N8\"  \"id\"  \"N14\" \"N34\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ord_mRMR <- mRMR.ranking[0:30]\n",
    "x30_mRMR <- X.tr[,ord_mRMR]\n",
    "names(x30_mRMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results interpretation and methods comparison\n",
    "\n",
    "As we can see, the ranking obtained in both filtering methods differs. This is due to additional phase done by the mRMR method which is characterized by the fact that if a feature is too much related with another one then is considered as a redundant variable thus the ranking will be changed. For instance, if we consider the second and third top features in the method \"correlation with the output\" and the mRMR method we can see that the third top feature isn't the same. In \"correlation with the output\" it is N24 but for mrMR it is N29. This is due to the fact that the feature N27 has a correlation of 0.1464617760 and the feature N24 has a correlation 0.1424325042 which is very similar and then considered has a redundant variable. Finally, we can see that in mRMR method, feature N24 will be outclassed by feature N29 that is less redundant with a correlation of 0.0845777330. To sum up, the general behaviour of both rankings are then quite similar excepting some features that are considered as redundant when their correlation score are very close which are therefore regressed in the top feature ranking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two filter methods that we have tackled here are complementary depending of the information that we want to extract. mRMR can somehow be seen as an enhancement of \"correlation with output\" method since it adds a post-processing method which remove features redundancies. Nevertheless, sometimes it could be interesting to not remove these redundancies which may remove an important desired feature. In this case, the selection of features with filter methods is independent of any machine learning algorithms. This is one of the reasons why no learning algorithm are used in the implemented filter methods algorithms. \n",
    "\n",
    "Instead, features are then selected on the basis of their scores in various statistical tests for their correlation with the outcome variable. The pseudo-code below represents the process of mRMR method which contains the \"correlation with output\" method (method 1) followed by the post-processing method which consists of removing redundancy. \n",
    "\n",
    "#### Pseudo-Code of filter methods\n",
    "   \n",
    "    X <- put all features except target\n",
    "    Y <- put only target\n",
    "    Init(size.CV, CV.err)\n",
    "\n",
    "    FOR(i TO number of folds in cross validation process):\n",
    "    DO:\n",
    "        X.tr, Y.tr <- createTrainingSet(X,Y)\n",
    "        X.ts, Y.ts <- createTestingSet(X,Y)\n",
    "        computeCorrelation(X.tr, Y.tr)\n",
    "        \n",
    "        # For \"Correlation with output\" method: Make the ranking regarding the correlations at this step. \n",
    "        \n",
    "        # For mRMR: Removal of redundancy process below. \n",
    "        \n",
    "        selectedFeature <- createEmptyList\n",
    "        candidates <- length(allFeatures)\n",
    "\n",
    "        FOR(j to numberOfFeatures):\n",
    "        DO:\n",
    "            computeRedudancyScore(candidates)\n",
    "            IF(there is a topFeature selected):\n",
    "            DO:\n",
    "                correlation <- computeCorrelation(topFeature against all other features left)\n",
    "                computeNewRedudancyScore(correlation(candidates), redudanceScore)\n",
    "                \n",
    "            mRMRscore <- correlationOfAllCandidates - redudancyScore\n",
    "            topFeatureSelected <- feature with highest correlation\n",
    "            RemoveFromCandidates(topFeatureSelected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper methods constitutes the second main category of feature selection methods. Comparing the filter methods, the main difference is that the learning algorithm is an entire part of the process. This difference is especially notable regarding to the computation time. Compared to filter methods, wrapper methods take way more time due to its high complexity. Indeed, wrapper methods is a searching problem which consists of finding the best features subset using a model to learn. To do that, different types of wrapper methods exist: \n",
    "- <b>Forward Selection:</b> this is an iterative method that starts from an empty subset to finally obtain the best ranking features subset. At each iteration, the feature that improves the best (which means that implies the lowest error rate) our model is added and stops until adding a feature does not improve the performance of the model or simply when there is no features left in case of only doing a features ranking.\n",
    "- <b>Backward Elimination:</b> somehow the contrary of Forward Selection. Here we start with the full set of features and removes the least significant feature at each iteration. We stop when removing any feature isn't improving the model. \n",
    "- <b>Recursive Feature elimination:</b> as its name said, this method repeatedly creates models and keeps aside the best or the worst performing feature at each iteration. The next model is constructed with these left features. This is then a recursive process which stops when all features are eliminated. Thus, the ranking is done in order of their elimination.\n",
    "\n",
    "In this document, the algorithm implemented is Forward Selection using Linear Regression as learning algorithm. All the main steps are highlighted in comments of the code. \n",
    "A summary of the wrapper methods process is summarized in the following figure (source: Saurav Kaushik (2016)): \n",
    "![Wrapper methods process](figures/wrapper.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> The Forward Selection algorithm takes a little bit of time to execute. Please be patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Rank  1  ; Selected feature:  21  ; CV error= 0.2441  ; std dev= 0.0064\"\n",
      "[1] \"Rank  2  ; Selected feature:  25  ; CV error= 0.2395  ; std dev= 0.0069\"\n",
      "[1] \"Rank  3  ; Selected feature:  28  ; CV error= 0.236  ; std dev= 0.0074\"\n",
      "[1] \"Rank  4  ; Selected feature:  27  ; CV error= 0.2328  ; std dev= 0.0084\"\n",
      "[1] \"Rank  5  ; Selected feature:  18  ; CV error= 0.2313  ; std dev= 0.0072\"\n",
      "[1] \"Rank  6  ; Selected feature:  20  ; CV error= 0.2284  ; std dev= 0.0072\"\n",
      "[1] \"Rank  7  ; Selected feature:  29  ; CV error= 0.2268  ; std dev= 0.0083\"\n",
      "[1] \"Rank  8  ; Selected feature:  7  ; CV error= 0.2261  ; std dev= 0.0092\"\n",
      "[1] \"Rank  9  ; Selected feature:  13  ; CV error= 0.2256  ; std dev= 0.0086\"\n",
      "[1] \"Rank  10  ; Selected feature:  19  ; CV error= 0.2249  ; std dev= 0.0085\"\n",
      "[1] \"Rank  11  ; Selected feature:  44  ; CV error= 0.2247  ; std dev= 0.0084\"\n",
      "[1] \"Rank  12  ; Selected feature:  11  ; CV error= 0.2245  ; std dev= 0.0086\"\n",
      "[1] \"Rank  13  ; Selected feature:  31  ; CV error= 0.2242  ; std dev= 0.0087\"\n",
      "[1] \"Rank  14  ; Selected feature:  3  ; CV error= 0.2241  ; std dev= 0.0085\"\n",
      "[1] \"Rank  15  ; Selected feature:  8  ; CV error= 0.2239  ; std dev= 0.0082\"\n",
      "[1] \"Rank  16  ; Selected feature:  23  ; CV error= 0.2239  ; std dev= 0.0082\"\n",
      "[1] \"Rank  17  ; Selected feature:  36  ; CV error= 0.2238  ; std dev= 0.0082\"\n",
      "[1] \"Rank  18  ; Selected feature:  43  ; CV error= 0.2238  ; std dev= 0.0083\"\n",
      "[1] \"Rank  19  ; Selected feature:  45  ; CV error= 0.2237  ; std dev= 0.0081\"\n",
      "[1] \"Rank  20  ; Selected feature:  10  ; CV error= 0.2237  ; std dev= 0.0081\"\n",
      "[1] \"Rank  21  ; Selected feature:  12  ; CV error= 0.2237  ; std dev= 0.0086\"\n",
      "[1] \"Rank  22  ; Selected feature:  37  ; CV error= 0.2237  ; std dev= 0.0085\"\n",
      "[1] \"Rank  23  ; Selected feature:  9  ; CV error= 0.2237  ; std dev= 0.0087\"\n",
      "[1] \"Rank  24  ; Selected feature:  42  ; CV error= 0.2237  ; std dev= 0.0087\"\n",
      "[1] \"Rank  25  ; Selected feature:  34  ; CV error= 0.2237  ; std dev= 0.0087\"\n",
      "[1] \"Rank  26  ; Selected feature:  46  ; CV error= 0.2237  ; std dev= 0.0087\"\n",
      "[1] \"Rank  27  ; Selected feature:  38  ; CV error= 0.2237  ; std dev= 0.0088\"\n",
      "[1] \"Rank  28  ; Selected feature:  41  ; CV error= 0.2237  ; std dev= 0.0088\"\n",
      "[1] \"Rank  29  ; Selected feature:  40  ; CV error= 0.2238  ; std dev= 0.0087\"\n",
      "[1] \"Rank  30  ; Selected feature:  2  ; CV error= 0.2238  ; std dev= 0.0088\"\n",
      "[1] \"Rank  31  ; Selected feature:  22  ; CV error= 0.2238  ; std dev= 0.0088\"\n",
      "[1] \"Rank  32  ; Selected feature:  30  ; CV error= 0.2238  ; std dev= 0.0089\"\n",
      "[1] \"Rank  33  ; Selected feature:  26  ; CV error= 0.2238  ; std dev= 0.0089\"\n",
      "[1] \"Rank  34  ; Selected feature:  32  ; CV error= 0.2239  ; std dev= 0.0089\"\n",
      "[1] \"Rank  35  ; Selected feature:  33  ; CV error= 0.2239  ; std dev= 0.0089\"\n",
      "[1] \"Rank  36  ; Selected feature:  15  ; CV error= 0.2239  ; std dev= 0.0088\"\n",
      "[1] \"Rank  37  ; Selected feature:  16  ; CV error= 0.224  ; std dev= 0.0089\"\n",
      "[1] \"Rank  38  ; Selected feature:  24  ; CV error= 0.224  ; std dev= 0.0089\"\n",
      "[1] \"Rank  39  ; Selected feature:  35  ; CV error= 0.2241  ; std dev= 0.0089\"\n",
      "[1] \"Rank  40  ; Selected feature:  5  ; CV error= 0.2241  ; std dev= 0.0089\"\n",
      "[1] \"Rank  41  ; Selected feature:  39  ; CV error= 0.2242  ; std dev= 0.0089\"\n",
      "[1] \"Rank  42  ; Selected feature:  14  ; CV error= 0.2244  ; std dev= 0.0089\"\n",
      "[1] \"Rank  43  ; Selected feature:  1  ; CV error= 0.225  ; std dev= 0.0093\"\n",
      "[1] \"Rank  44  ; Selected feature:  17  ; CV error= 0.2263  ; std dev= 0.0121\"\n",
      "[1] \"Rank  45  ; Selected feature:  4  ; CV error= 1.5013  ; std dev= 4.0283\"\n",
      "[1] \"Rank  46  ; Selected feature:  6  ; CV error= 1.1583  ; std dev= 2.9442\"\n"
     ]
    }
   ],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "selected<-NULL\n",
    "\n",
    "# For every feature (column)\n",
    "for (round in 1:n) { \n",
    "  candidates<-setdiff(1:n,selected)\n",
    "  \n",
    "  CV.err<-matrix(0,nrow=length(candidates),ncol=10)\n",
    "  \n",
    "  # For every candidates   \n",
    "  for (j in 1:length(candidates)) {\n",
    "    features_to_include<-c(selected,candidates[j])\n",
    "    \n",
    "    # 10-fold cross-validation process  \n",
    "    for (i in 1:10) {\n",
    "        \n",
    "      # Testing Set   \n",
    "      i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "      X.ts<-X[i.ts,features_to_include,drop=F]  \n",
    "      Y.ts<-Y[i.ts]  \n",
    "      \n",
    "      # Training Set   \n",
    "      i.tr<-setdiff(1:N,i.ts)\n",
    "      X.tr<-X[i.tr,features_to_include,drop=F]\n",
    "      Y.tr<-Y[i.tr]\n",
    "      \n",
    "      DS<-cbind(X.tr,target=Y.tr)\n",
    "      \n",
    "      # Learning algorithm\n",
    "      model<- lm(target~.,DS) # Linear model\n",
    "      Y.hat.ts<- predict(model,X.ts)\n",
    "      \n",
    "      # Error computation (Evaluation)\n",
    "      CV.err[j,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  CV.err.mean<-apply(CV.err,1,mean)\n",
    "  CV.err.sd<-apply(CV.err,1,sd)\n",
    "    \n",
    "  # Get the feature with the minimum error which is the feature that improves the model the best \n",
    "  selected_current<-which.min(CV.err.mean)    \n",
    "  selected<-c(selected,candidates[selected_current])\n",
    "    \n",
    "  wrap.ranking<-selected  \n",
    "  print(paste(\"Rank \",round,\" ; Selected feature: \",candidates[selected_current],\" ; CV error=\",round(CV.err.mean[selected_current],digits=4), \" ; std dev=\",round(CV.err.sd[selected_current],digits=4)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21</li>\n",
       "\t<li>25</li>\n",
       "\t<li>28</li>\n",
       "\t<li>27</li>\n",
       "\t<li>18</li>\n",
       "\t<li>20</li>\n",
       "\t<li>29</li>\n",
       "\t<li>7</li>\n",
       "\t<li>13</li>\n",
       "\t<li>19</li>\n",
       "\t<li>44</li>\n",
       "\t<li>11</li>\n",
       "\t<li>31</li>\n",
       "\t<li>3</li>\n",
       "\t<li>8</li>\n",
       "\t<li>23</li>\n",
       "\t<li>36</li>\n",
       "\t<li>43</li>\n",
       "\t<li>45</li>\n",
       "\t<li>10</li>\n",
       "\t<li>12</li>\n",
       "\t<li>37</li>\n",
       "\t<li>9</li>\n",
       "\t<li>42</li>\n",
       "\t<li>34</li>\n",
       "\t<li>46</li>\n",
       "\t<li>38</li>\n",
       "\t<li>41</li>\n",
       "\t<li>40</li>\n",
       "\t<li>2</li>\n",
       "\t<li>22</li>\n",
       "\t<li>30</li>\n",
       "\t<li>26</li>\n",
       "\t<li>32</li>\n",
       "\t<li>33</li>\n",
       "\t<li>15</li>\n",
       "\t<li>16</li>\n",
       "\t<li>24</li>\n",
       "\t<li>35</li>\n",
       "\t<li>5</li>\n",
       "\t<li>39</li>\n",
       "\t<li>14</li>\n",
       "\t<li>1</li>\n",
       "\t<li>17</li>\n",
       "\t<li>4</li>\n",
       "\t<li>6</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21\n",
       "\\item 25\n",
       "\\item 28\n",
       "\\item 27\n",
       "\\item 18\n",
       "\\item 20\n",
       "\\item 29\n",
       "\\item 7\n",
       "\\item 13\n",
       "\\item 19\n",
       "\\item 44\n",
       "\\item 11\n",
       "\\item 31\n",
       "\\item 3\n",
       "\\item 8\n",
       "\\item 23\n",
       "\\item 36\n",
       "\\item 43\n",
       "\\item 45\n",
       "\\item 10\n",
       "\\item 12\n",
       "\\item 37\n",
       "\\item 9\n",
       "\\item 42\n",
       "\\item 34\n",
       "\\item 46\n",
       "\\item 38\n",
       "\\item 41\n",
       "\\item 40\n",
       "\\item 2\n",
       "\\item 22\n",
       "\\item 30\n",
       "\\item 26\n",
       "\\item 32\n",
       "\\item 33\n",
       "\\item 15\n",
       "\\item 16\n",
       "\\item 24\n",
       "\\item 35\n",
       "\\item 5\n",
       "\\item 39\n",
       "\\item 14\n",
       "\\item 1\n",
       "\\item 17\n",
       "\\item 4\n",
       "\\item 6\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21\n",
       "2. 25\n",
       "3. 28\n",
       "4. 27\n",
       "5. 18\n",
       "6. 20\n",
       "7. 29\n",
       "8. 7\n",
       "9. 13\n",
       "10. 19\n",
       "11. 44\n",
       "12. 11\n",
       "13. 31\n",
       "14. 3\n",
       "15. 8\n",
       "16. 23\n",
       "17. 36\n",
       "18. 43\n",
       "19. 45\n",
       "20. 10\n",
       "21. 12\n",
       "22. 37\n",
       "23. 9\n",
       "24. 42\n",
       "25. 34\n",
       "26. 46\n",
       "27. 38\n",
       "28. 41\n",
       "29. 40\n",
       "30. 2\n",
       "31. 22\n",
       "32. 30\n",
       "33. 26\n",
       "34. 32\n",
       "35. 33\n",
       "36. 15\n",
       "37. 16\n",
       "38. 24\n",
       "39. 35\n",
       "40. 5\n",
       "41. 39\n",
       "42. 14\n",
       "43. 1\n",
       "44. 17\n",
       "45. 4\n",
       "46. 6\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 21 25 28 27 18 20 29  7 13 19 44 11 31  3  8 23 36 43 45 10 12 37  9 42 34\n",
       "[26] 46 38 41 40  2 22 30 26 32 33 15 16 24 35  5 39 14  1 17  4  6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrap.ranking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 features with Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'N20'</li>\n",
       "\t<li>'N24'</li>\n",
       "\t<li>'N27'</li>\n",
       "\t<li>'N26'</li>\n",
       "\t<li>'N17'</li>\n",
       "\t<li>'N19'</li>\n",
       "\t<li>'N28'</li>\n",
       "\t<li>'N6'</li>\n",
       "\t<li>'N12'</li>\n",
       "\t<li>'N18'</li>\n",
       "\t<li>'N43'</li>\n",
       "\t<li>'N10'</li>\n",
       "\t<li>'N30'</li>\n",
       "\t<li>'N2'</li>\n",
       "\t<li>'N7'</li>\n",
       "\t<li>'N22'</li>\n",
       "\t<li>'N35'</li>\n",
       "\t<li>'N42'</li>\n",
       "\t<li>'N44'</li>\n",
       "\t<li>'N9'</li>\n",
       "\t<li>'N11'</li>\n",
       "\t<li>'N36'</li>\n",
       "\t<li>'N8'</li>\n",
       "\t<li>'N41'</li>\n",
       "\t<li>'N33'</li>\n",
       "\t<li>'N45'</li>\n",
       "\t<li>'N37'</li>\n",
       "\t<li>'N40'</li>\n",
       "\t<li>'N39'</li>\n",
       "\t<li>'N1'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'N20'\n",
       "\\item 'N24'\n",
       "\\item 'N27'\n",
       "\\item 'N26'\n",
       "\\item 'N17'\n",
       "\\item 'N19'\n",
       "\\item 'N28'\n",
       "\\item 'N6'\n",
       "\\item 'N12'\n",
       "\\item 'N18'\n",
       "\\item 'N43'\n",
       "\\item 'N10'\n",
       "\\item 'N30'\n",
       "\\item 'N2'\n",
       "\\item 'N7'\n",
       "\\item 'N22'\n",
       "\\item 'N35'\n",
       "\\item 'N42'\n",
       "\\item 'N44'\n",
       "\\item 'N9'\n",
       "\\item 'N11'\n",
       "\\item 'N36'\n",
       "\\item 'N8'\n",
       "\\item 'N41'\n",
       "\\item 'N33'\n",
       "\\item 'N45'\n",
       "\\item 'N37'\n",
       "\\item 'N40'\n",
       "\\item 'N39'\n",
       "\\item 'N1'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'N20'\n",
       "2. 'N24'\n",
       "3. 'N27'\n",
       "4. 'N26'\n",
       "5. 'N17'\n",
       "6. 'N19'\n",
       "7. 'N28'\n",
       "8. 'N6'\n",
       "9. 'N12'\n",
       "10. 'N18'\n",
       "11. 'N43'\n",
       "12. 'N10'\n",
       "13. 'N30'\n",
       "14. 'N2'\n",
       "15. 'N7'\n",
       "16. 'N22'\n",
       "17. 'N35'\n",
       "18. 'N42'\n",
       "19. 'N44'\n",
       "20. 'N9'\n",
       "21. 'N11'\n",
       "22. 'N36'\n",
       "23. 'N8'\n",
       "24. 'N41'\n",
       "25. 'N33'\n",
       "26. 'N45'\n",
       "27. 'N37'\n",
       "28. 'N40'\n",
       "29. 'N39'\n",
       "30. 'N1'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"N20\" \"N24\" \"N27\" \"N26\" \"N17\" \"N19\" \"N28\" \"N6\"  \"N12\" \"N18\" \"N43\" \"N10\"\n",
       "[13] \"N30\" \"N2\"  \"N7\"  \"N22\" \"N35\" \"N42\" \"N44\" \"N9\"  \"N11\" \"N36\" \"N8\"  \"N41\"\n",
       "[25] \"N33\" \"N45\" \"N37\" \"N40\" \"N39\" \"N1\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x30_wrap <- X.tr[0:30]\n",
    "names(x30_wrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results interpretation and comparison with filter methods\n",
    "\n",
    "The ranking obtained differs from the one obtained by the filter methods. This can be explained by the fact that a learning algorithm is used to establish the ranking. More precisely, at the first step we consider all the features and select the one wich performs the best in our prediction i.e. which will have the minimum CV.error, here we can see that it is the feature 21. Once this feature selected, we take this feature and we combine it with all the other features to see how well the combination of the two performs. As we can see the second best feature will be 25 because the combination of the feature 21 with 25 is the one giving the minimum CV.error. Then, we take the previous feature selected, here 25, and combine it to all others and we do the algorithm until we don't have any features left. Finally we can see that the feature 4 for example, tends to perform horribly because the only combination possibe in the end is with the feature 6 which also perfom not well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection conclusion: filter methods vs wrapper methods\n",
    "\n",
    "In conclusion, here are a table representing the main differences and the advantages (+) and drawbacks (-) of using such method or another. \n",
    "\n",
    "| Filter methods  | Wrapper methods    |\n",
    "|------------|-------------|\n",
    "|  Measure the relevance of features by their correlation    |     measure the usefulness of a subset of feature by actually training a model on it   |\n",
    "|  (+) Much faster as they do not involve training the models    |  (-) computationally very expensive      |\n",
    "|  (-) Might fail to find the best subset of features   |   (+) might provide the best subset of features     |\n",
    "|  (-) Assume no dependency between the evaluated features   |   (+) evaluation take into account the information dependency between the evaluated features     |\n",
    "|  (-) No relationship with the classifier   |   (+) better for classification problem because the classifier itself as evaluation criteria     |\n",
    "|  (+) Thanks to its fastness, suitable for applications that mostly deal with the storage and retrieval of high dimensional datasets.   |   (-) Can need a large number of applications and tests to train to outperform filters    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Model selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are asked to create 3 different model selection procedure to compare their performance. The three following models implemented are Random Forest, SVM and Decision Trees. To create those models, we are using the results obtained in the previous section in the feature selection (FS), i.e. the top 30 features found previously. Thus, a comparison of the model's performance using the different methods of feature selection is also done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert training set to the good format \n",
    "trainSet <- as.character(Y.tr)\n",
    "trainSet <- as.factor(trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is a model used for classification but also regression used mostly in supervised learning methods. Basically, the tree is contitued of nodes and leaves wherein the solutions to a problem are the leaves and the nodes represent a certain decision to make in other words each nodes represent a certain feature. The advantages from using a decision are the following:\n",
    "- a better visulation/comprehension of the data\n",
    "- non linear relationship from data doesn't affect the performance\n",
    "- it is fast\n",
    "- it can handle numerical and categorial variable\n",
    "\n",
    "and the disadvantages from such a model are:\n",
    "- overfitting\n",
    "- the variance in the data can create unstable tree \n",
    "- a biased tree can be created if a certain class/feature dominate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using correlation with output for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.619266055045872\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with Decision Trees method using correlation with output (filter) for feature selection\n",
    "rpart.model <- rpart(trainSet~., data = x30)\n",
    "\n",
    "# Prediction \n",
    "rpart.predTrain <- predict(rpart.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(rpart.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mRMR for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.631498470948012\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with Decision Trees method using mRMR (filter) for feature selection\n",
    "rpart.model <- rpart(trainSet~., data = x30_mRMR)\n",
    "\n",
    "# Prediction \n",
    "rpart.predTrain <- predict(rpart.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(rpart.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Forward Selection for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.622324159021407\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with Decision Trees method using Forward Selection (wrapper) for feature selection\n",
    "rpart.model <- rpart(trainSet~., data = x30_wrap)\n",
    "\n",
    "# Prediction \n",
    "rpart.predTrain <- predict(rpart.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(rpart.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Random forest is a model used for regression and classification problem. More precisely, it is an aggregation of decision trees (see figure below from Jocelyn D'Souza (2018) which illustrates random forest with 2 decision trees) which will produce a more generalized model such that we avoid the overfitting problem that could result from a simple decision tree. To put simply, in a random forest, multiple decision trees are constructed and each decision tree will contain only a subset of the features the purpose here is to make higly uncorraleted trees because the average error of a random ensemble of errors is zero. Finally it will do as much random split as possible in the trees such that we get a better prediction.\n",
    "\n",
    "![Random forests](figures/randomForest.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using correlation with output for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.672018348623853\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with randomForest method using correlation with output (filter) for feature selection\n",
    "RF.model <- randomForest(trainSet~.,data = x30,ntree=1000)\n",
    "\n",
    "# Prediction \n",
    "RF.predTrain <- predict(RF.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(RF.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mRMR for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.675076452599388\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with randomForest method using mRMR (filter) for feature selection\n",
    "RF.model <- randomForest(trainSet~.,data = x30_mRMR,ntree=1000)\n",
    "\n",
    "# Prediction \n",
    "RF.predTrain <- predict(RF.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(RF.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Forward Selection for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.67737003058104\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with randomForest method using Forward Selection (wrapper) for feature selection\n",
    "RF.model <- randomForest(trainSet~.,data = x30_wrap,ntree=1000)\n",
    "\n",
    "# Prediction \n",
    "RF.predTrain <- predict(RF.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(RF.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVM) are supervised learning models that are efficient to resolve classication problems or regression problems. SVM is based on the idea of finding an hyperplane that best separates the features into different\n",
    "domains. SVMs are a generalization of linear classifiers. Moreover, SVM is the only linear model which can classify data which is not linearly separable as shown in the figure below (source: 2017, Haydar Ali Ismail, Medium.com). The main reason to use an SVM is then when the problem might not be linearly separable. In that case, we will have to use an SVM with a non linear kernel (e.g. RBF).\n",
    "\n",
    "![SVM](figures/svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> The SVM model takes a little bit of time to execute. Please be patient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using correlation with output for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.562691131498471\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with SVM method using correlation with output (filter) for feature selection\n",
    "svm.model <- svm(trainSet~., data = x30, kernel = \"linear\", type = \"C-classification\",scale = FALSE)\n",
    "\n",
    "# Prediction \n",
    "svm.predTrain <- predict(svm.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(svm.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mRMR for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.652140672782875\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with SVM method using mRMR (filter) for feature selection\n",
    "svm.model <- svm(trainSet~., data = x30_mRMR, kernel = \"linear\", type = \"C-classification\",scale = FALSE)\n",
    "\n",
    "# Prediction \n",
    "svm.predTrain <- predict(svm.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(svm.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Forward Selection for FS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy of the model on training dataset: 0.675076452599388\"\n"
     ]
    }
   ],
   "source": [
    "# Create the model with SVM method using Forward Selection (wrapper) for feature selection\n",
    "svm.model <- svm(trainSet~., data = x30_wrap, kernel = \"linear\", type = \"C-classification\",scale = FALSE)\n",
    "\n",
    "# Prediction \n",
    "svm.predTrain <- predict(svm.model, X.ts, type = \"class\")\n",
    "\n",
    "# Compute accuracy of the model\n",
    "acc <- mean(svm.predTrain == Y.ts) \n",
    "print(paste0(\"Accuracy of the model on training dataset: \", acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results interpretation and comparison\n",
    "\n",
    "The results obtained for each method is summed up in the table below:\n",
    "\n",
    "| FS method â†“ | Decision Trees | Random Forest | SVM |\n",
    "|------|------|------|------|\n",
    "| Correlation with output  | 61.93% | 67.20%| 56.27% |\n",
    "| mRMR  | 63.15% | 67.50% | 65.21% |\n",
    "| Forward Selection  | 62.23%| 67.73% | 67.5% |\n",
    "\n",
    "#### Comparing Feature Selection methods\n",
    "The general behaviour that we can remark is that all these accuracies are around 60%. Nevertheless, depending of the methods used, they are fluctuating a lot. Generally, as theoritically said in the previous section, using wrapper methods for classification enhances the accuracy. This assertion is somehow verified. Indeed, the only case where the best accuracy is not obtained when using Forward Selection for feature selection is for the decision trees model. \n",
    "Concerning the mRMR feature selection method, it should upgrade the results compared to \"correlation with output\" method since it doesn't use redundant features. We see that it works pretty well for SVM since the accuracy increased from 56% to 65%. Moreover, it also increases for the 2 other methods, sign that redundant features are overall flawing the classification. \n",
    "In summary, for such classification problem, the best feature selection methods to use are ordered as following: Forward Selection (Wrapper) > mRMR (Filter) > Correlation with output (Filter). \n",
    "\n",
    "#### Comparing learning methods\n",
    "As we can see, random forest performs better than decision trees because it is an ensemble of multiple decision trees. Since it uses the bagging method (weak learner are coupled to produce a strong learner) and use always a different subset of the features in each decision tree, it avoids the overfitting problem and produce less variance of the estimation. Thereafter, we can see that random forest also performs better than SVM. These results can be explained by the fact that our dataset contains too much data. More precisely, random forests tend to perform better on large datasets whereas SVM seems to do better in small dataset (less than 10000 rows). Indeed, the only method of the third performing better using less features as data is SVM: around 64% using the top 10 (instead of 30) features using \"Correlation with output\" method. \n",
    "\n",
    "Furthermore, comparing the computational times of these different methods, decision trees leads obviously based on this criteria. Nevertheless, as seen before, this is the fastest method but the less accurate one. Then, comparing random forests and SVM, random forest seems to perform faster on this huge dataset since SVM is often worthwhile training on a smaller dataset first, and tuning your model's hyper-parameter's. Of course, the complexity of random forests is based on the number of trees chosen and could increase a lot and could exceed SVM if using more trees. \n",
    "\n",
    "In conclusion, the methods can overall be ordered as following in term of <b>accuracy</b>: Random Forests > SVM > Decision Trees. Concerning <b>computation times</b>, it is ordered as: Decision Trees > Random Forests > SVM. So that, to get a good balance between both, random forests seems to be the best method to adopt over the three presented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Combination of models\n",
    "\n",
    "In this section, we are trying to combine models to enhance our prediction accuracy. These models can be the same type such as using multiple decision trees but can also combine different types of models. The idea behind that technique is similar to combining the knowledge of different experts, called <i>weak learners</i>, to become a unique one called <i>strong learner</i>. This combination of models is also called <i>ensemble learning</i>. Basically, the simple ensemble techniques are based on averaging (or weighted average) the results but can also be based on a vote system where the majority vote (i.e. a vote = a model's result) is taken in account. Thus, ensemble learning is a technique that helps to reduce noise, variance, and bias. More accuratly, the two main techniques of ensembling are called <b>bagging</b> and <b>boosting</b>. However before understanding these techniques, the notion of <i>bootstrapping</i> has to be understood.\n",
    "\n",
    "Bootstrap refers to random sampling with replacement. In other words, we choose $n$ observations (rows) where each row is selected with replacement from the original dataset so that each row is equally likely (same probabilities) to be selected in each iteration which can help to better understand the mean and standard deviation from the dataset. Now that bootstrap is understood, we can define bagging and boosting techniques. \n",
    "\n",
    "- <b>Bagging:</b> Bagging is the application of the Bootstrap procedure to a high-variance machine learning algorithm, typically decision trees. In other words, once we have the bootstrap samples, we build a model for each sample. Finally, the  results of these multiple models are combined using average or majority voting. In particular, random forests use this method combining several decision trees.  \n",
    "\n",
    "\n",
    "- <b>Boosting:</b> Boosting is an iterative technique which adjusts the weight of an observation based on the last classification. Therefore, unlike bagging where each model is acting independently, here each model that runs dictates what features the next model will focus on. Thus, the first algorithm is trained on the entire dataset and the subsequent algorithms are built by fitting the residuals of the first algorithm. \n",
    "\n",
    "### AdaBoost implementation\n",
    "\n",
    "Here below, we are implementing the <b>AdaBoost</b> algorithm which is a boosting algorithm. At first, we will produce a weak classifier (the misclassification error rate is slightly better than random). More precisely, the model will be created based on a dataset sample given a certain probability based on weights. In the beginning, the weights are all the same but updated at each iteration. Once the prediciton done, we will compute the error of prediction given the real dataset and this error will be used to update the weight $a$: \n",
    "$$a_j = log(\\frac{1 - MME_{emp}^j}{MME_{emp}^j})$$\n",
    "\n",
    "which will give us the importance of the model at step $j$. The importance will then be used to update the weights $w$:\n",
    "$$w_i = w_i*exp(alpha_j * MME_j)$$\n",
    "\n",
    "herein, the weights is the one associated to each observations thus it will put more emphasis on the misclassified observations such that the next iteration will create a sample focusing more on these observation. In other words, by updating these weights we will try to do a better classification than before thus creating in the end a better model by doing a weighted majority vote:\n",
    "$$model_{boosted} = sign(\\sum^m_{j=1} a_j h_j(x,a_n)$$\n",
    "\n",
    "which will produced the final predicition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification single tree= 0.4105778 \n",
      "Misclassification boosting= 0.4020177 \n"
     ]
    }
   ],
   "source": [
    "full_training<- data.frame(apply(full_training,2,replace_na_with_mean_value))\n",
    "nsample <- nrow(full_training)\n",
    "full_training[full_training==0] <- -1\n",
    "halfsample <- floor(nrow(full_training)/2)\n",
    "Nsample<-nrow(full_training)\n",
    "full_trainings <- full_training[sample(nrow(full_training)),]\n",
    "train <- full_trainings[1:halfsample, ]\n",
    "test <- full_trainings[(halfsample+1):Nsample, ]\n",
    "Ntrain <- dim(train)[1]\n",
    "Ntest  <- dim(test)[1] \n",
    "w<-rep(1/Ntrain,Ntrain)\n",
    "\n",
    "# first compute a regular tree misclassification rate\n",
    "set.seed(555)\n",
    "\n",
    "# Create the model with Decision Trees method\n",
    "rpart.model <- rpart(target~., data = train)\n",
    "\n",
    "# Prediction \n",
    "pred <- sign(predict(rpart.model, test))\n",
    "\n",
    "misc.tree <- sum(as.integer(test$target != sign(pred)))/length(pred)\n",
    "\n",
    "# boosting initialisation\n",
    "T<-15\n",
    "\n",
    "wmisc<-rep(NA,T);\n",
    "alpha<-rep(NA,T)\n",
    "pred.test<-rep(0,Ntest)\n",
    "\n",
    "for (t in 1:T)\n",
    "{\n",
    "  set.seed(700+t)\n",
    "  \n",
    "  # generate new sample set accoring to their weights\n",
    "  I<-sample(seq(1,Ntrain),prob=w,replace=TRUE)\n",
    "  \n",
    "  # Build a new tree accordingly\n",
    "  rpart.model <- rpart(target~., data = train[I,])\n",
    "\n",
    "  # predict\n",
    "  pred.train  <- sign(predict(rpart.model,train))\n",
    "  wmisc[t] <- sum(w*as.integer(train$target != pred.train))/sum(w)\n",
    "    \n",
    "  # update weigths\n",
    "  alpha[t]<-log((1-wmisc[t])/wmisc[t])\n",
    "  w<- w*exp(alpha[t]*as.integer(train$target!= pred.train))\n",
    "  \n",
    "  # update predictions\n",
    "  pred.test<-sign(pred.test+alpha[t]*predict(rpart.model,test))\n",
    "}\n",
    "\n",
    "# compute overall boosting misclassification rate\n",
    "misc.boosting <- mean(test$target != sign(pred.test))\n",
    "\n",
    "\n",
    "cat(\"Misclassification single tree=\",misc.tree,\"\\n\")\n",
    "cat(\"Misclassification boosting=\",misc.boosting,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: when running the above cell for the first time, the results shown are 0.397 missclassification rate for one tree and 0.415 for multiple trees for an unknown reason. If we rerun the cell, we always obtain the same results presented in the following section (0.4105778 for single tree missclassification and 0.4020177 for multiple trees missclassification). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results interpretation\n",
    "\n",
    "Due to the AdaBoost algorithm explained above we can see that there is less misclassification with 15 trees in opposite of 1 tree. Indeed, we started from 0.4105778 rate of missclassification when using one tree to 0.4020177 when using multiple trees. This optimisation can be due to the fact that the weight are correctly updated on the observation that were missclassified thus focusing more on these observations such that it results in a better classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Submission to Kaggle's competition\n",
    "\n",
    "We have submitted our prediction to the Kaggle's competition and have obtained a score of <b>0.66804</b> (66.804% accuracy, before final results) by using Random Forests learning algorithm and Forward Selection for Feature Selection. Our group name in the leaderboard is \"Bui & Singh\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In conclusion, we have first implemented 3 methods of feature selection: correlation with output, mRMR and Forward Selection where the 2 first are filter methods and the last one is wrapper methods. Subsequently, we have used the top features returned by these 3 methods to apply it to the 3 predictive models that we have implemented: Decision Trees, Random Forests and SVM. The different results obtained have shown that Forward Selection was globally the best feature selection method for a classification problem. Moreover, comparing the performance of these 3 models, random forests has a constant high accuracy (around 67%) whether the feature selection method used and performs better overall. Finally, we have used the AdaBoost algorithm as combination of models technique to try to enhance the overall performance. In this part, we have tried to predict with a single decision tree and compared it to the prediction with 15 decisions tree. The observation done is that the missclassification rate is a bit less significant than the prediction while using one tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
